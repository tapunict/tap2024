{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kafka Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It makes it simple to quickly define connectors that move large collections of data into and out of Kafka. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Kafka Connect can ingest entire databases or collect metrics from all your application servers into Kafka topics, making the data available for stream processing with low latency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An export job can deliver data from Kafka topics into secondary storage and query systems or into batch systems for offline analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**A common framework for Kafka connectors** \n",
    "\n",
    "Kafka Connect standardizes integration of other data systems with Kafka, simplifying connector development, deployment, and management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://images.ctfassets.net/8vofjvai1hpv/4io4iF1i7C6vaHt3w0EIal/b608a11ae2613cd91a226680c6796322/blog_IntroducingConfluentHub.png)\n",
    "https://www.confluent.io/hub/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Distributed and standalone modes** \n",
    "\n",
    "Scale up to a large, centrally managed service supporting an entire organization or scale down to development, testing, and small production deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://cdn.confluent.io/wp-content/uploads/kafka-connect-2.png)\n",
    "https://www.confluent.io/blog/create-dynamic-kafka-connect-source-connectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**REST interface**\n",
    "Submit and manage connectors to your Kafka Connect cluster via an easy to use REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://img.youtube.com/vi/4xWPDXhBi3g/maxresdefault.jpg)\n",
    "https://developer.confluent.io/learn-kafka/kafka-connect/rest-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Automatic offset management** \n",
    "\n",
    "With just a little information from connectors, Kafka Connect can manage the offset commit process automatically so connector developers do not need to worry about this error prone part of connector development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://static.wikia.nocookie.net/fa4cdf31-15f4-492a-ad62-4cec313ba39b/scale-to-width/370)\n",
    "\n",
    "https://harrypotter.fandom.com/f/p/4400000000003402981/r/4400000000011097584"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Distributed and scalable by default** \n",
    "\n",
    "Kafka Connect builds on the existing group management protocol. More workers can be added to scale up a Kafka Connect cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://www.oreilly.com/api/v2/epubs/9781787122765/files/assets/842ab4a5-f79c-43d4-bd61-96b2eb53676a.png)\n",
    "https://www.oreilly.com/library/view/modern-big-data/9781787122765/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Streaming/batch integration** \n",
    "\n",
    "Leveraging Kafka's existing capabilities, Kafka Connect is an ideal solution for bridging streaming and batch data systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://i.imgflip.com/7icsk4.jpg)\n",
    "[NicsMeme](https://imgflip.com/i/7icsk4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Connect Standalone Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A worker can be run using the following command\n",
    "```bash\n",
    "> bin/connect-standalone.sh config/connect-standalone.properties [connector1.properties connector2.properties ...]\n",
    "```\n",
    "\n",
    "The list of the few "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A File to File example\n",
    "\n",
    "Goal: Create a kafka connect process that reads from a file and writes to another file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Configuration\n",
    "\n",
    "```properties\n",
    "bootstrap.servers=kafkaServer:9092\n",
    "key.converter=org.apache.kafka.connect.json.JsonConverter\n",
    "value.converter=org.apache.kafka.connect.json.JsonConverter\n",
    "key.converter.schemas.enable=true\n",
    "value.converter.schemas.enable=true\n",
    "offset.storage.file.filename=/tmp/connect.offsets\n",
    "offset.flush.interval.ms=10000\n",
    "plugin.path=/opt/kafka/libs/connect-file-3.5.0.jar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Source\n",
    "\n",
    "```properties\n",
    "name=local-file-source\n",
    "connector.class=FileStreamSource\n",
    "tasks.max=1\n",
    "file=test.txt\n",
    "topic=connect-test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Sink\n",
    "\n",
    "```properties\n",
    "name=local-file-sink\n",
    "connector.class=FileStreamSink\n",
    "tasks.max=1\n",
    "file=test.sink.txt\n",
    "topics=connect-test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```bash\n",
    "# Assuming Kafka Server and ZooKeeper are up and running\n",
    "\n",
    "docker exec -it kafkaServer kafka-topics.sh --bootstrap-server kafkaServer:9092 --create --topic connect-test \n",
    "# Start a new container (please note that referenced file are adjusted to work in docker)\n",
    "docker run --rm -e KAFKA_ACTION=connect-standalone -e KAFKA_WORKER_PROPERTIES=connect-standalone.properties -e KAFKA_CONNECTOR_PROPERTIES=\"config/connect-file-source.properties config/connect-file-sink.properties\" --network tap --name kafkaConnect tap:kafka\n",
    "\n",
    "# In another tab open a consumer\n",
    "docker run --rm  -e KAFKA_ACTION=consumer -e KAFKA_TOPIC=connect-test --network tap   -it tap:kafka\n",
    "\n",
    "# In another tab open a shell inside the kafkaConnect \n",
    "docker exec -it kafkaConnect /bin/bash\n",
    "cd /tmp/\n",
    "echo \"hello\" > my-test.txt\n",
    "\n",
    "# In another tab open another shell inside the kafkaConnect \n",
    "docker exec -it kafkaConnect /bin/bash\n",
    "cd /tmp/\n",
    "tail -f test.sink.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# API Rest\n",
    "https://kafka.apache.org/documentation/#connect_rest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "# Open a new tab \n",
    "docker exec -it kafkaConnect /bin/bash\n",
    "curl -s -XGET http://localhost:8083/connectors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Biblio\n",
    "- https://blog.softwaremill.com/do-not-reinvent-the-wheel-use-kafka-connect-4bcabb143292\n",
    "- https://dev.to/thegroo/kafka-connect-crash-course-1chd\n",
    "- https://data-flair.training/blogs/kafka-connect/\n",
    "- https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/\n",
    "- https://data-flair.training/blogs/kafka-connect/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": "true",
   "footer": "<div class=\"tap-footer\"> *** Technologies for advanced programming (TAP) - 2023 ***</div>",
   "header": "<div class=\"tap-header\"></div>",
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
